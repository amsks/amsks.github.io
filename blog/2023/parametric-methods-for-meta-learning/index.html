<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Parametric Methods for Meta-Learning | Aditya Mohan</title> <meta name="author" content="Aditya Mohan"> <meta name="description" content="Personal Website of Aditya Mohan "> <meta name="keywords" content="Reinforcement Learning, Meta-Learning, AutoML, AutoRL"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8E%A8&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://amsks.github.io/blog/2023/parametric-methods-for-meta-learning/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="//"><span class="font-weight-bold">Aditya </span>Mohan</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Hey there!</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Curriculum Vitae</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Parametric Methods for Meta-Learning</h1> <p class="post-meta">July 7, 2023</p> <p class="post-tags"> <a href="//blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="//blog/category/meta-learning"> <i class="fas fa-tag fa-sm"></i> meta-learning</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="back-box-adaptation">Back-Box Adaptation</h2> <p>These are a set of approaches that treat step 1 as an inference problem and thus, training a Neural Network to represent \(p(\phi_i \mid \mathcal{D}^{tr}, \theta)\) i.e a way to estimate \(\phi_i\) and then use that as a parameter to optimize for a new task. The deterministic way to go about it would be to take point estimates</p> \[\phi_i = f_\theta (\mathcal{D}^{tr}_i)\] <p>Thus, we can treat \(f_\theta(.)\) as a neural network parameterized by \(\theta\) which takes the training data as an input, sequential or batched, and outputs the task-specific parameters \(\phi_i\) which are then used by another neural network \(g_{\phi_i} (.)\) to predict the outputs on a new dataset. Thus, we can essentially treat this as a supervised learning problem with our optimization being</p> \[\begin{aligned} &amp; \max_\theta \sum_{\mathcal{T_i}} \sum_{(x,y) \sim \mathcal{D_i}^{test}} \log g_{\phi_i} (y\mid x) \\ = &amp; \max_\theta \sum_{\mathcal{T_i}} \mathcal{L}(f_\theta(\mathcal{D^{tr}_i}), \mathcal{D_i^{test}}) \end{aligned}\] <p>To make this more tractable, \(\phi\) can be replaced by a sufficient statistic \(h_i\) instead of all the parameters. Some ANN architectures that work well with this approach are LSTMs, as shown in the work of <a href="http://proceedings.mlr.press/v48/santoro16.pdf" rel="external nofollow noopener" target="_blank">Santoro et. al</a>, feedforward networks with averaging as shown by <a href="https://arxiv.org/abs/1807.01613" rel="external nofollow noopener" target="_blank">Ramalho et. al</a>, Having inner task learners and outer meta-learners i.e <a href="https://arxiv.org/abs/1703.00837" rel="external nofollow noopener" target="_blank">Meta-Networks byMukhdalai</a> e.t.c. I am personally fascinated by the use of transformer architectures in this domain. The advantage of this approach is that it is expressive and easy to combine with other techniques like supervised learning, reinforcement learning e.t.c. However, the optimization bit is challenging and not the best solution from the onset for every kind of problem. Thus, our step-by-step approach would be:</p> <ol> <li>Sample Task \(\mathcal{T}_i\) ( a sequential stream or mini-batches )</li> <li>Sample Disjoint Datasets \(\mathcal{D^{tr}_i}\),\(\mathcal{D^{test}_i}\) from \(\mathcal{D}_i\)</li> <li>Compute \(\phi_i \leftarrow f_\theta(\mathcal{D^{tr}_i})\)</li> <li>Update \(\theta\) using \(\nabla_\theta\mathcal{L}(\phi_i, \mathcal{D^{test}_i})\)</li> </ol> <h2 id="optimization-based-approaches">Optimization-Based Approaches</h2> <p>This set treats the prediction of \(\phi_i\) as an optimization procedure and then differentiates through that optimization process to get a \(\phi_i\) that leads to good performance. The method can be summarized into the surrogates sums of maximization of observing the training data given \(\phi_i\) and the maximization of getting \(\phi_i\) given our model parameters \(\theta\).</p> \[\max_{\phi_i} \log p(\mathcal{D^{tr}_i} \mid \phi_i ) + \log p(\phi_i \mid \theta)\] <p>The second part of the above summation is our prior and the first part is a likelihood. Thus, our next question is the form of this prior that might be useful. In deep learning, one good way to incorporate priors is through the initialization of hyperparameters, or fine-tuning. Thus, we can take \(\theta\) as a pre-trained parameter and run gradient descent on it</p> \[\phi \leftarrow \theta - \alpha \nabla_\theta \mathcal{L} (\theta, \mathcal{D^{tr}})\] <p>One popular way to do this for image classification is to have a feature extractor pre-trained on some datasets like ImageNet and then fine-tune its output to our problem. The aim in optimization-based approaches is to get to a sweet-spot in the multidimensional parameter space \(\mathbf{\Phi} = {\phi_1, \phi_2, .., \phi_n}\) such that our model becomes independent of the loss function and the training data, and this is called Model-Agnostic Meta-Learning. Thus, now our procedure becomes</p> <ol> <li>Sample Task \(\mathcal{T}_i\) ( a sequential stream or mini-batches )</li> <li>Sample Disjoint Datasets \(\mathcal{D^{tr}_i}\),\(\mathcal{D^{test}_i}\) from \(\mathcal{D}_i\)</li> <li>Optimize \(\phi_i \leftarrow f_\theta(\mathcal{D^{tr}_i})\)</li> <li>Update \(\theta\) using \(\nabla_\theta\mathcal{L}(\phi_i, \mathcal{D^{test}_i})\)</li> </ol> <p>For our optimization process, let’s define our final task specific parameter as</p> \[\phi = u(\theta, \mathcal{D^{tr}})\] <p>And now, our optimization target becomes</p> \[\begin{aligned} &amp; \min_\theta \mathcal{L}(\phi, \mathcal{D^{test}}) \\ = &amp; \min_\theta \mathcal{L} \big (u(\theta, \mathcal{D^{tr}}), \mathcal{D^{test}} \big) \end{aligned}\] <p>This optimization can be achieved by differentiating our loss w.r.t our meta-parameters \(\theta\) and then performing an inner differentiation w.r.t \(\phi\):</p> \[\frac{d\mathcal{L} (\phi, \mathcal{D^{test}} ) }{d \theta} = \nabla _{\bar{\phi}} \mathcal{L} (\bar{\phi}, \mathcal{D^{test}} ) \mid_{\bar{\phi} = u(\theta, \mathcal{D^{tr}}) } d_\theta \big ( u(\theta, \mathcal{D^{tr}} ) \big )\] <p>Now, if we use our optimization update for \(u (.)\) then we get:</p> \[\begin{aligned} &amp; u(\theta, \mathcal{D^{tr}} ) = \theta - \alpha \,\, d_\theta \big( L(\theta, \mathcal{D^{tr}}) \big ) \\ \implies &amp; d_\theta \big ( u(\theta, \mathcal{D^{tr}} ) \big ) = \mathbf{1} - \alpha \, d^2_\theta \big (L(\theta, \mathcal{D^{tr}}) \big ) \end{aligned}\] <p>Thus, when we substitute the hessian in the derivative equation we get:</p> \[\begin{aligned} \frac{d\mathcal{L} (\phi, \mathcal{D^{test}} ) }{d \theta} &amp; = \bigg (\nabla _{\bar{\phi}} \mathcal{L} (\bar{\phi}, \mathcal{D^{test}} ) \mid_{\bar{\phi} = u(\theta, \mathcal{D^{tr}}) } \bigg ). \bigg ( \mathbf{1} - \alpha \, d^2_\theta \big (L(\theta, \mathcal{D^{tr}}) \big ) \bigg ) \\ &amp; = \nabla _{\bar{\phi}} \mathcal{L} (\bar{\phi}, \mathcal{D^{test}} ) \mid_{\bar{\phi} = u(\theta, \mathcal{D^{tr}}) } - \alpha\,\, \bigg( \nabla _{\bar{\phi}} \mathcal{L} (\bar{\phi}, \mathcal{D^{test}} ) . d^2_\theta \big (L(\theta, \mathcal{D^{tr}}) \big ) \bigg ) \mid_{\bar{\phi} = u(\theta, \mathcal{D^{tr}}) } \end{aligned}\] <p>We now have a matrix product on the right which can be made more efficient and turn out ot be easier to compute than the full hessian of the network. Thus, this process is tractable. one really interesting thing that comes out of this is that we can also view this model-agnostic approach and the optimization update as a computation graph! Thus, we can say</p> \[\phi_i = \theta - f(\theta, \mathcal{D_i^{tr}}, \nabla_\theta \mathcal{L} )\] <p>Now, we can train an ANN to output the gradient \(f(.)\) , and thus, this allows us to mix the optimization procedure with the black-box adaptation process. Moreover, MAML approaches show a better performance on the omniglot dataset since they are optimizing for the model-agnostic points. It has been shown by <a href="https://arxiv.org/abs/1710.11622" rel="external nofollow noopener" target="_blank">Finn and Levine</a> that MAML can approximate any function of \(\mathcal{D_i^{tr}}\) and \(x^{ts}\) give:</p> <ul> <li>Non-zero \(\alpha\)</li> <li>Loss function gradient does not lose information about the label</li> <li>Data-points in \(\mathcal{D_i^{tr}}\) are unique</li> </ul> <p>Thus, MAML is able to inject inductive bias without losing expressivity.</p> <h3 id="inferece">Inferece</h3> <p>To better understand why MAML works well, we need to look through probabilistic lenses again to say that the meta-parameters \(\theta\) are inducing some kinds of prior knowledge into our system and so our learning objective would be to maximize the probability of observing the data \(\mathcal{D}_i\), given our meta-parameters \(\theta\)</p> \[\max_\theta \log \prod_i p(\mathcal{D}_i| \theta )\] <p>This can be further written as the sum of the probabilities of \(\mathcal{D_i}\) given our model-specific parameters \(\phi_i\), and the probability of seeing each \(\phi_i\) given our prior knowledge \(\theta\) :</p> \[\max _\theta \prod_i \int p(\mathcal{D_i} |\phi_i) p(\phi_i|\theta) d\phi_i\] <p>And now, we can estimate the probability of seeing each \(\phi_i\) given our prior knowledge \(\theta\) using a Maximum A-Posteriori (MAP) estimate \(\hat{\phi}\), so that</p> \[\max_\theta \log \prod_i p(\mathcal{D}_i| \theta ) \approx \max_\theta \log \prod_i p(\mathcal{D}_i|\hat{\phi}_i) p(\hat{\phi} | \theta)\] <p><a href="https://regijs.github.io/papers/laa96.pdf" rel="external nofollow noopener" target="_blank">It has been shown</a> that, for likelihoods that are Gaussian in \(\phi_i\), gradient descent with early stopping corresponds exactly to maximum a-posteriori inference under a Gaussian prior with mean initial samples. This estimation is exact in the linear case, and the variance in non-linear cases is determined by the order of the derivative. Thus, by limiting the computation to second derivatives, MAML is able to maintain a fairly good MAP inference estimate and so, MAML approximates hierarchical Bayesian Inference. We can also use other kinds of priors like:</p> <ul> <li> <table> <tbody> <tr> <td> <a href="https://arxiv.org/abs/1909.04630" rel="external nofollow noopener" target="_blank">Explicit Gaussian Prior</a>: $$\phi \leftarrow \min_{\phi’} \mathcal{L} (\phi’, \mathcal{D^{tr}}) + \frac{\lambda}{2}</td> <td> </td> <td>\theta - \phi’</td> <td> </td> <td>^2$$</td> </tr> </tbody> </table> </li> <li> <a href="https://arxiv.org/abs/1807.08912" rel="external nofollow noopener" target="_blank">Bayesian Linear Regression</a> on learned features</li> <li>Convex optimization on learned features</li> <li>Ridge or logistic regression</li> <li>Support Vector Machines</li> </ul> <h3 id="challenge-1-choosing-architecture">Challenge 1: Choosing Architecture</h3> <p>The major bottleneck in this process is the inner gradient step and so, we want to chosse an architecture that is effective for this inner step. One idea, called <a href="https://arxiv.org/abs/1806.06927" rel="external nofollow noopener" target="_blank">Auto-Meta</a> is to adopt the progressive neural architecture search to find optimal architectures for meta-learners i.e combine AutoML with Gradient-Based Meta-Learning. The interesting results of this were:</p> <ul> <li>They found highlynon-standard architectures, both deep and narrow</li> <li>They found architectures very different from the ones used for supervised learning</li> </ul> <h3 id="challenge-2-handling-instabilities">Challenge 2: Handling Instabilities</h3> <p>Another challenge comes from the instability that can come from the complicated Bi-Level optimization procedure. One way of mitigating this is to learn the inner vector learning rate and then tune the outer learning rate :</p> <ul> <li> <a href="https://arxiv.org/abs/1707.09835" rel="external nofollow noopener" target="_blank">Meta-Stochastic Gradient Descent</a> is a meta-learner that can learn initialization, learner update direction, and learning rate, all in a single closed-loop process</li> <li> <a href="https://arxiv.org/abs/1905.07435" rel="external nofollow noopener" target="_blank">AlphaMAML</a> incorporates an online hyperparameter adaptation scheme that eliminates the need to tune meta-learning and learning rates</li> </ul> <p>Another idea idea is to optimize only a subset of parameters in the innter loop:</p> <ul> <li> <a href="https://arxiv.org/abs/1802.03596" rel="external nofollow noopener" target="_blank">DEML</a> jointly learns a concept generator, a meta-learner, and a concept discriminator. The concept generator abstracts representation of each instance of training data, the meta-learner performs few-shot learning on this instance and the concept discriminator recognizes the concept pertaining to each instance</li> <li> <a href="https://arxiv.org/abs/1810.03642" rel="external nofollow noopener" target="_blank">CAVIA</a> partitions the model parameters into context parameters that serve as additional input to the model and are adapted on individual tasks and shared parameters that are meta-trained and shared across tasks. Thus, during test time only the context parameters need to be updated, which is a lower-dimensional search problem compared to all the model parameters</li> </ul> <p>In <a href="https://arxiv.org/pdf/1810.09502.pdf" rel="external nofollow noopener" target="_blank">MAML++</a> the authors ablate the various ideas and issues of MAML and then propose a new framework that addresses these issues. Some significant points were the de-coupling of the inner loop learning rate and the outer updates, the addition of batch normalization to each and every step and greedy updates.</p> <h3 id="challenge-3-managing-compute-and-memory">Challenge 3: Managing Compute and Memory</h3> <p>The backpropagation through many inner-gradient steps adds computational and memory overhead that is hard to deal with. One idea to mitigate this is to approximate the derivative of \(\phi_i\) w.r.t \(\theta\). This is a crude approximation and works well for few-shot learning problem, but fails in more complex problems like imitation learning. Another direction is to try to not compute the gradient at all and use the <a href="https://arxiv.org/abs/1909.04630" rel="external nofollow noopener" target="_blank">implicit function theorem</a>→ Let’s take our function \(\phi\) as the explicit gaussian representation :</p> \[\phi = u(\theta, \mathcal{D^{tr}}) = \underset{\phi'}{\text{argmin}} \mathcal{L}(\phi', \mathcal{D^{tr}}) + \frac{\lambda}{2} ||\phi' - \theta ||^2\] <p>Let our optimization function be</p> \[G(\phi', \theta ) = \mathcal{L}(\phi', \mathcal{D^{tr}}) + \frac{\lambda}{2} ||\phi' - \theta ||^2\] <p>Finding the \(\text{argmin}\) of the this function implies that the gradient w.r.t \(\phi\) is \(0\) i.e</p> \[\begin{aligned} &amp; \nabla_{\phi'} G(\phi', \theta) \big|_{\phi' = \phi} = 0 \\ \implies &amp; \nabla_\phi L(\phi) + \lambda(\phi - \theta ) = 0 \\ \implies &amp; \phi = \theta - \frac{1}{\lambda} \nabla_\phi L(\phi) \end{aligned}\] <p>Thus, our derivative now becomes</p> \[\begin{aligned} &amp; \frac{d \phi}{d \theta } = \mathbf{1} - \frac{1}{\lambda} \nabla_\phi^2 L(\phi) \frac{d \phi}{d \theta } \\ \therefore\,\,\,&amp; \frac{d \phi}{d \theta } = \bigg [\mathbf{1} + \frac{1}{\lambda} \nabla_\phi^2 L(\phi) \bigg ] ^{-1} \end{aligned}\] <p>Thus, we can compute this without going through the inner optimization process and it works only on the assumption that the out function \(G(\phi', \theta)\) has an \(\text{argmin}\) , to begin with.</p> </div> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2024 Aditya Mohan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank"></a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: November 21, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>